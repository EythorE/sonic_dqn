log:
  name: "episodic_memory_revised_scenario"
  logdir: "./runs/debug/"
  log_frequency: 10000
  save_steps: 200000

    #resume: "./runs/runs/log_240630-1533/2000000.pt"
n_steps: 12800000 # calculated as n_training_steps * training_interval
training_interval: 2 # numer of steps between sgd optimization steps
replay_buffer_fill_samples: 100 #101 # number of episodes to fill buffer with before starting
replay_memory_size: 2000 # size of the replay_buffer in number of episodes
copy_steps: 40000 # steps between online_dqn -> training_dqn, 10_000 * training_interval
eps_max: 0.9 # exploration start/max probability
eps_min: 0.1 # exploration end/min probability
eps_decay_steps: 400000 # steps until eps_min, 100_000 * training_interval
batch_size: 10
Tmax: 50 # maximum number of time steps for attention

dqn:
  device: "cuda" # cpu or cuda
  discount_rate: 0.99 # aka gamma
  max_grad_norm: 20 # limit the norm of the gradients, mitigates exploding gradients
# optimizer:
#   optim: "Adam"
#   lr: 0.001
#   fused: True
  optimizer: 
    optim: "SGD"
    lr: 0.001
    momentum: 0.95
    nesterov: True

environment:
  render_mode: None # human or None
  scenario: "./scenario.json"
  max_episode_steps: 5400 #90s #10800 # 3 minutes, 3 * 60 * 60
  n_action_repeats: 20 # number of steps to repeat every action
    #frame_diff_length: 2 #5 # motion blur current frame with frame frame_diff length before

